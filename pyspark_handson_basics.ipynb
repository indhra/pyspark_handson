{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0182e2a8",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a3a716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629f30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/05 10:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://mac:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkBasics</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10c3eb2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"SparkBasics\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea679bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x10c3eb2e0>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddfb5ea",
   "metadata": {},
   "source": [
    "# creating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1231c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 25, 'Engineer'), ('Bob', 30, 'Manager'), ('Charlie', 35, 'Analyst')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: Simple list to DataFrame\n",
    "data = [(\"Alice\", 25, \"Engineer\"),\n",
    "        (\"Bob\", 30, \"Manager\"), \n",
    "        (\"Charlie\", 35, \"Analyst\")]\n",
    "\n",
    "columns = [\"name\", \"age\", \"role\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfd511cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|     _1| _2|      _3|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "|Charlie| 35| Analyst|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data\n",
    "                           )\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ed2c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: string (nullable = true)\n",
      " |-- _2: long (nullable = true)\n",
      " |-- _3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af218300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "|Charlie| 35| Analyst|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, \n",
    "                           columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33740107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- role: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7da9cfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "512d5043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'age', 'role']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74372e57",
   "metadata": {},
   "source": [
    "# explicit data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8154a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StringType(), True), StructField('age', IntegerType(), True), StructField('role', StringType(), True)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType, IntegerType, StructField,StructType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\",IntegerType(), True),\n",
    "    StructField(\"role\",StringType(), True)\n",
    "])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66598213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "|Charlie| 35| Analyst|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_type = spark.createDataFrame(data, schema)\n",
    "df_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23001f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- role: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_type.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3fd56",
   "metadata": {},
   "source": [
    "# selecting, filtering, sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b02545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Alice| 25|\n",
      "|    Bob| 30|\n",
      "|Charlie| 35|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name','age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea392dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-------+\n",
      "|   name|age|   role|\n",
      "+-------+---+-------+\n",
      "|Charlie| 35|Analyst|\n",
      "+-------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7026d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-------+\n",
      "|name|age|   role|\n",
      "+----+---+-------+\n",
      "| Bob| 30|Manager|\n",
      "+----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.role =='Manager').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a5b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "|Charlie| 35| Analyst|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy('age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a621652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|Charlie| 35| Analyst|\n",
      "|    Bob| 30| Manager|\n",
      "|  Alice| 25|Engineer|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e7e6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "|Charlie| 35| Analyst|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.age.asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67509fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------+\n",
      "|   name|age|    role|\n",
      "+-------+---+--------+\n",
      "|Charlie| 35| Analyst|\n",
      "|  Alice| 25|Engineer|\n",
      "|    Bob| 30| Manager|\n",
      "+-------+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy('role').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753a544a",
   "metadata": {},
   "source": [
    "# column operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d977e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db450145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|   name|age_plus_five|\n",
      "+-------+-------------+\n",
      "|  Alice|           30|\n",
      "|    Bob|           35|\n",
      "|Charlie|           40|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name', (col(\"age\") + 5).alias('age_plus_five')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a81b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|   name|age_plus_fiveish|\n",
      "+-------+----------------+\n",
      "|  Alice|            30.2|\n",
      "|    Bob|            35.2|\n",
      "|Charlie|            40.2|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1= df.select('name', (col('age')+5.2).alias('age_plus_fiveish'))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75446ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age_plus_fiveish: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab2ae4",
   "metadata": {},
   "source": [
    "# grouping and aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4f22901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('James', 'Sales', 'NY', 90000, 34, 10000),\n",
       " ('Michael', 'Sales', 'NY', 86000, 56, 20000),\n",
       " ('Robert', 'Sales', 'CA', 81000, 30, 23000),\n",
       " ('Maria', 'Finance', 'CA', 90000, 24, 23000),\n",
       " ('Raman', 'Finance', 'CA', 99000, 40, 24000),\n",
       " ('Scott', 'Finance', 'NY', 83000, 36, 19000),\n",
       " ('Jen', 'Finance', 'NY', 79000, 53, 15000),\n",
       " ('Jeff', 'Marketing', 'CA', 80000, 25, 18000),\n",
       " ('Kumar', 'Marketing', 'NY', 91000, 50, 21000)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    (\"James\", \"Sales\", \"NY\", 90000, 34, 10000),\n",
    "    (\"Michael\", \"Sales\", \"NY\", 86000, 56, 20000),\n",
    "    (\"Robert\", \"Sales\", \"CA\", 81000, 30, 23000),\n",
    "    (\"Maria\", \"Finance\", \"CA\", 90000, 24, 23000),\n",
    "    (\"Raman\", \"Finance\", \"CA\", 99000, 40, 24000),\n",
    "    (\"Scott\", \"Finance\", \"NY\", 83000, 36, 19000),\n",
    "    (\"Jen\", \"Finance\", \"NY\", 79000, 53, 15000),\n",
    "    (\"Jeff\", \"Marketing\", \"CA\", 80000, 25, 18000),\n",
    "    (\"Kumar\", \"Marketing\", \"NY\", 91000, 50, 21000)\n",
    "]\n",
    "columns = [\"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e76b3709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, columns)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6df7a588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+--------+\n",
      "|state|sum(salary)|max(age)|\n",
      "+-----+-----------+--------+\n",
      "|   NY|     429000|      56|\n",
      "|   CA|     350000|      40|\n",
      "+-----+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, avg, min, max\n",
    "\n",
    "df.groupBy('state').agg(sum('salary'),max('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a0f3463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------+\n",
      "|department|highest_bonus|lowest_bonus|\n",
      "+----------+-------------+------------+\n",
      "|     Sales|        23000|       10000|\n",
      "|   Finance|        24000|       15000|\n",
      "| Marketing|        21000|       18000|\n",
      "+----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('department').agg(max('bonus').alias('highest_bonus'), min('bonus').alias('lowest_bonus')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58c5e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   NY|    5|\n",
      "|   CA|    4|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\n",
    "    \"state\"\n",
    ").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d0dec",
   "metadata": {},
   "source": [
    "# window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a3b5f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70412366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.classic.window.WindowSpec object at 0x10c4233d0>\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy('department').orderBy('Salary')\n",
    "print(window_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05d8e88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "|employee_name|department|state|salary|age|bonus|salary_rank|\n",
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|          1|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|          2|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|          3|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|          4|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|          1|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|          2|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|          1|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|          2|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|          3|\n",
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('salary_rank', rank().over(window_spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79406f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "|employee_name|department|state|salary|age|bonus|aged_person|\n",
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|          1|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|          2|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|          3|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|          4|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|          1|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|          2|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|          1|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|          2|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|          3|\n",
      "+-------------+----------+-----+------+---+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = Window.partitionBy('department').orderBy(df.age.desc())\n",
    "df.withColumn('aged_person',rank().over(window_spec)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d783857a",
   "metadata": {},
   "source": [
    "# joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90d0a547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_data = [(\"Finance\", 10), (\"Marketing\", 20), (\"Sales\", 30)]\n",
    "dept_columns = [\"dept_name\", \"dept_id\"]\n",
    "dept_df = spark.createDataFrame(dept_data, dept_columns)\n",
    "\n",
    "emp_data = [(1,\"John\",10), (2,\"Maria\",20), (3,\"David\",10)]\n",
    "emp_columns = [\"emp_id\", \"name\", \"emp_dept_id\"]\n",
    "emp_df = spark.createDataFrame(emp_data, emp_columns)\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a18d144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+\n",
      "|emp_id| name|emp_dept_id|\n",
      "+------+-----+-----------+\n",
      "|     1| John|         10|\n",
      "|     2|Maria|         20|\n",
      "|     3|David|         10|\n",
      "+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7302158e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+---------+-------+\n",
      "|emp_id| name|emp_dept_id|dept_name|dept_id|\n",
      "+------+-----+-----------+---------+-------+\n",
      "|     1| John|         10|  Finance|     10|\n",
      "|     3|David|         10|  Finance|     10|\n",
      "|     2|Maria|         20|Marketing|     20|\n",
      "+------+-----+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = emp_df.join(dept_df, dept_df.dept_id == emp_df.emp_dept_id, how='inner')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "031b1f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+---------+-------+\n",
      "|emp_id| name|emp_dept_id|dept_name|dept_id|\n",
      "+------+-----+-----------+---------+-------+\n",
      "|     1| John|         10|  Finance|     10|\n",
      "|     2|Maria|         20|Marketing|     20|\n",
      "|     3|David|         10|  Finance|     10|\n",
      "+------+-----+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = emp_df.join(dept_df, dept_df.dept_id == emp_df.emp_dept_id, how='left')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ae77eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+---------+-------+\n",
      "|emp_id| name|emp_dept_id|dept_name|dept_id|\n",
      "+------+-----+-----------+---------+-------+\n",
      "|     3|David|         10|  Finance|     10|\n",
      "|     1| John|         10|  Finance|     10|\n",
      "|     2|Maria|         20|Marketing|     20|\n",
      "|  NULL| NULL|       NULL|    Sales|     30|\n",
      "+------+-----+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = emp_df.join(dept_df, dept_df.dept_id == emp_df.emp_dept_id, how='right')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "69dc103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----------+---------+-------+\n",
      "|emp_id| name|emp_dept_id|dept_name|dept_id|\n",
      "+------+-----+-----------+---------+-------+\n",
      "|     1| John|         10|  Finance|     10|\n",
      "|     3|David|         10|  Finance|     10|\n",
      "|     2|Maria|         20|Marketing|     20|\n",
      "|  NULL| NULL|       NULL|    Sales|     30|\n",
      "+------+-----+-----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = emp_df.join(dept_df, dept_df.dept_id == emp_df.emp_dept_id, how='outer')\n",
    "joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f65ef",
   "metadata": {},
   "source": [
    "# caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c656cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd3e4ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[employee_name: string, department: string, state: string, salary: bigint, age: bigint, bonus: bigint]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af413e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "039f8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53a41d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "joined.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a8e4c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[emp_id: bigint, name: string, emp_dept_id: bigint, dept_name: string, dept_id: bigint]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aab03681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|        Raman|   Finance|   CA| 99000| 40|24000|\n",
      "|        Scott|   Finance|   NY| 83000| 36|19000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformation - lazy\n",
    "older = df.filter(df.age>30)\n",
    "\n",
    "# action - triggers job\n",
    "older.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5fcdef",
   "metadata": {},
   "source": [
    "# distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a214cd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "572122c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increase partitions  - shuffle\n",
    "\n",
    "df2 = df.repartition(10)\n",
    "df2.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df46f317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df.coalesce(2)\n",
    "df3.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08957520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
